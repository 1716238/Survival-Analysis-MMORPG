{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from lifelines import KaplanMeierFitter\r\n",
    "from lifelines.plotting import rmst_plot\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.feature_selection import RFECV\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.metrics import roc_curve\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.patches as mpatches\r\n",
    "import matplotlib.patches as mpatches\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "import plotly.graph_objects as go\r\n",
    "import seaborn as sns\r\n",
    "import warnings\r\n",
    "\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART I - Exploratory Data Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Read in CSV\r\n",
    "avatar_history = pd.read_csv('data/wowah_data.csv')\r\n",
    "\r\n",
    "## Examine data contents\r\n",
    "avatar_history.info()\r\n",
    "avatar_history.head()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "avatar_history.rename(columns = lambda x: x.strip(), inplace = True)\r\n",
    "avatar_history.columns"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def time_transform(x):\r\n",
    "    \"Function to split the date and time\"\r\n",
    "    y = x.split()[0]\r\n",
    "    return y[:-2] + '20' + y[-2:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Create new features date and time using the function above\r\n",
    "avatar_history['date'] = avatar_history['timestamp'].apply(time_transform)\r\n",
    "avatar_history['time'] = avatar_history['timestamp'].apply(lambda x: x.split()[1][:-4] + '0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create datetime features \r\n",
    "avatar_history['timestamp'] = pd.to_datetime(avatar_history['timestamp'])\r\n",
    "avatar_history['Month'] = avatar_history['timestamp'].dt.month\r\n",
    "avatar_history['Day'] = avatar_history['timestamp'].dt.dayofyear\r\n",
    "avatar_history['Weekday'] = avatar_history['timestamp'].dt.weekday"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Table of feature description\r\n",
    "## Find the number of unique entries for each feature\r\n",
    "number_of_characters = avatar_history['char'].nunique()\r\n",
    "number_of_levels = avatar_history['level'].nunique()\r\n",
    "number_of_races = avatar_history['race'].nunique()\r\n",
    "number_of_classes = avatar_history['charclass'].nunique()\r\n",
    "number_of_zones = avatar_history['zone'].nunique()\r\n",
    "number_of_guilds = avatar_history['guild'].nunique()\r\n",
    "number_of_timestamps = avatar_history['timestamp'].nunique()\r\n",
    "\r\n",
    "## Append and print the unique entries for each feature\r\n",
    "data = []\r\n",
    "for x in avatar_history.columns:\r\n",
    "    print(\"The number of unique \" + str(x) + \" is \" + str(avatar_history[x].nunique()) + \".\")\r\n",
    "    data.append(avatar_history[x].nunique())\r\n",
    "\r\n",
    "## Create table using plotly \r\n",
    "### Create an array and transpose values to make it a two-column format\r\n",
    "data = np.array(data)\r\n",
    "data = data.transpose()\r\n",
    "\r\n",
    "### Create plotly table object\r\n",
    "feature_information = go.Figure(data = [go.Table(\r\n",
    "    header = dict(values = ['Unique Characters', 'Unique Levels',\r\n",
    "                            'Unique Races', 'Unique Classes',\r\n",
    "                            'Unique Zones', 'Unique Guilds',\r\n",
    "                            'Unique Timestamps'],\r\n",
    "                  line_color = 'darkslategray',\r\n",
    "                  fill_color = 'lightskyblue',\r\n",
    "                  align = 'left'),\r\n",
    "    cells = dict(values = data,\r\n",
    "                 line_color = 'darkslategray',\r\n",
    "                 fill_color = 'lightcyan',\r\n",
    "                 align = 'left'))\r\n",
    "])\r\n",
    "\r\n",
    "feature_information.update_layout(width = 800, height = 300, title = 'Table 1: Feature description')\r\n",
    "feature_information.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most players are level 1 with 11598 out of 37354 character entries. This can be explained by the use of alternate characters, which are used as mules in major towns to sell and trade items between others. Also, with such a right-skewed distribution it may be informative for game developers to put more effort into the level 1 – 30 zones. There appears to be a steady decrease from 1 to 60 until 70, which was the max level before the WOTLK expansion. Finally, a peak at 80, which is the latest max level. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the Distribution of Levels\r\n",
    "## Create data segment - get the latest snapshot of levels\r\n",
    "level_dist = avatar_history.groupby('char')['level'].max()\r\n",
    "\r\n",
    "## Figure parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3})\r\n",
    "\r\n",
    "ax = sns.distplot(level_dist, kde_kws = {\"color\": \"green\", \"lw\": 4, \"label\": \"KDE\"},\r\n",
    "                  hist_kws = {\"linewidth\": 6,\r\n",
    "                              \"alpha\": 1, \"color\": \"pink\",\r\n",
    "                              'label': 'Histogram'})\r\n",
    "\r\n",
    "plt.xlabel('Levels', fontsize = 24)\r\n",
    "plt.ylabel('Frequency', fontsize = 24)\r\n",
    "plt.title('Distribution of Levels', fontsize = 24)\r\n",
    "number_of_ticks = [1, 10, 20, 30, 40, 50, 60, 70, 80]\r\n",
    "plt.xticks(number_of_ticks, fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "## Add annotations for statistics\r\n",
    "plt.text(80, 0.175, 'Min: ' + str(round(level_dist.value_counts().min(),1)) , size = 18, color = 'black')\r\n",
    "plt.text(80, 0.185, 'Mean: ' + str(round(level_dist.value_counts().mean(),1)) , size = 18, color = 'black')\r\n",
    "plt.text(80, 0.195, 'Max: ' + str(round(level_dist.value_counts().max(),1)) , size = 18, color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def featureDistribution_DF(feature):\r\n",
    "    \"\"\"Acquires a sorted dataframe of a selected featue which is categorized by char ID\"\"\"\r\n",
    "    feature_dist = avatar_history.groupby('char')[feature].max().value_counts()\r\n",
    "    sorted_feature_dist = pd.DataFrame(feature_dist)\r\n",
    "    sorted_feature_dist.columns = ['Count']\r\n",
    "    sorted_feature_dist.index.names = [feature]\r\n",
    "    return sorted_feature_dist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The zones which occupy WoW are not for individual levels but comprises level intervals. The top three level intervals are 0-9, 10 – 19, and 70-79. Such that having insight into how the population is divided in these intervals, further supports our initial reasoning to provide more development time in these early-level zones."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the level intervals \r\n",
    "## Discretize the levels into intervals\r\n",
    "bins = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80])\r\n",
    "\r\n",
    "## Apply the bins and create a new feature level_intervals\r\n",
    "avatar_history['level_interval'] = np.digitize(avatar_history['level'],bins)\r\n",
    "\r\n",
    "mapped_levels = {1: '0-9', 2: '10-19',\r\n",
    "     3: '20-29', 4: '30-39',\r\n",
    "     5: '40-49', 6: '50-59',\r\n",
    "     7: '60-69', 8: '70-79',\r\n",
    "     9: '80'}\r\n",
    "\r\n",
    "avatar_history['level_interval'] = avatar_history['level_interval'].map(mapped_levels)\r\n",
    "\r\n",
    "## Create a sorted dataframe of the level_interval feature\r\n",
    "sorted_level_interval_dist = featureDistribution_DF('level_interval')\r\n",
    "\r\n",
    "## Plot parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\r\n",
    "\r\n",
    "ax = sns.barplot(x = sorted_level_interval_dist['Count'],\r\n",
    "                 y = sorted_level_interval_dist.index, \r\n",
    "                 edgecolor = 'pink')\r\n",
    "\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Level Ranges', fontsize = 24)\r\n",
    "plt.title('Distribution of Level Ranges', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\r\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\r\n",
    "color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When players create their characters, they have a choice in selecting the race and class. Having data on their selections provides developers with insight to properly manage what classes should be monitored more and helps the game balance team to decide on why these certain classes or races are picked – Are they strong, weak, or people enjoy the themes of the classes. Should we spend more time on their race-specific starting zones due to their selection? The player base selects Blood Elves, Warriors, and Orc Warriors, as their popular choices in races, classes, and race-class combinations, respectively.    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Race Distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the race distribution\r\n",
    "sorted_race_dist = featureDistribution_DF('race')\r\n",
    "\r\n",
    "## Plot parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "textprops = dict(size = 22 )\r\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ffb3cc']\r\n",
    "\r\n",
    "plt.pie(sorted_race_dist['Count'], labels = sorted_race_dist.index,\r\n",
    "        autopct = '%1.1f%%', startangle = 90, textprops = textprops, colors = colors)\r\n",
    "\r\n",
    "plt.title('Distribution of Races', fontsize = 24)\r\n",
    "plt.axis('equal') \r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class Distributions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the class distribution\r\n",
    "sorted_class_dist = featureDistribution_DF('charclass')\r\n",
    "\r\n",
    "## Plot Parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\r\n",
    "ax = sns.barplot( x = sorted_class_dist['Count'],\r\n",
    "                  y = sorted_class_dist.index, edgecolor = 'pink')\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Classes', fontsize = 24)\r\n",
    "plt.title('Distribution of Classes', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\r\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\r\n",
    "color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Race + Class Combinations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the popular class / race combinations\r\n",
    "## Create dataframes for the race and class combinations\r\n",
    "race_class_dist = avatar_history.groupby('char')['race', 'charclass'].max()\r\n",
    "tmp_df = pd.DataFrame(race_class_dist)\r\n",
    "tmp_df.columns = ['Race', 'Class']\r\n",
    "tmp_df.index.names = ['charID']\r\n",
    "\r\n",
    "race_class_df = pd.DataFrame(tmp_df['Class'].values.astype(str),\r\n",
    "             tmp_df['Race'].values.astype(str), columns = ['Class'])\r\n",
    "\r\n",
    "race_class_df.index.names = ['Race']\r\n",
    "\r\n",
    "## Apply a whitespace to combine both race and class features\r\n",
    "race_class_df['Class']= race_class_df['Class'].apply(lambda x: \"{}{}\".format(' ', x))\r\n",
    "\r\n",
    "## Create the new race+class feature\r\n",
    "race_class_df['race+class'] = race_class_df.index.str.cat(race_class_df.values)\r\n",
    "\r\n",
    "## Sort by frequency \r\n",
    "ah_pop = race_class_df.assign(freq = race_class_df.groupby('race+class')['race+class'].transform('count'))\\\r\n",
    "  .sort_values(by = ['freq','race+class'],ascending = [False,True]).loc[:,['race+class']]\r\n",
    "\r\n",
    "## Plot parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\r\n",
    "ax = sns.countplot( y = ah_pop['race+class'], palette = 'bright', edgecolor = 'pink' )\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Races and Classes', fontsize = 24)\r\n",
    "plt.title('Distribution of Race and Class Combinations', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 14)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width(), i.get_y() + 0.9, \\\r\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', fontsize = 16,\r\n",
    "color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identifying population bottlenecks is important for optimizing server stability, but investigating which zones are populated is crucial in delegating resources into what aspects of the game players are enjoying. The game is divided into Player vs Environment and Player vs Player content. The top two zones are hubs where players can trade items or sign up for quests. The third is a major PvE raid dungeon where players embark on a quest to clear the opposing forces.    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Top 20 Popular Zones"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the top 20 popular zones\r\n",
    "## Sort by frequent zones\r\n",
    "ah_zf = avatar_history.assign(freq = avatar_history.groupby('zone')['zone'].transform('count'))\\\r\n",
    "  .sort_values(by = ['freq','zone'],ascending = [False , True]).loc[:,['zone']]\r\n",
    "\r\n",
    "## Create dataframe for top 20 popular zones\r\n",
    "zone_dist = ah_zf['zone'].value_counts()\r\n",
    "sorted_zone_dist = pd.DataFrame(zone_dist)\r\n",
    "sorted_zone_dist.columns = ['Count']\r\n",
    "sorted_zone_dist.index.names = ['zone']\r\n",
    "\r\n",
    "## Plot the expected variance\r\n",
    "plt.figure(figsize = (20, 10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 2})\r\n",
    "ax = sns.barplot( x = sorted_zone_dist['Count'][0:20],\r\n",
    "                  y = sorted_zone_dist.index[0:20], palette = 'bright', edgecolor = 'pink')\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Zones', fontsize = 24)\r\n",
    "plt.title('Top 20 Popular Zones', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches[0:20]:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches[0:20]:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width(), i.get_y() + 0.6, \\\r\n",
    "            str(round((i.get_width() / total) *100, 2)) + '%', fontsize = 16,\r\n",
    "color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guild Distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are roughly 500 guilds created - The largest guild has a population of 1796 members, and the average guild has 73 members. Similar to the class distribution in earlier, guilds follow the same breakdown. Higher-level content requires an abundant amount of people requiring 25 or more and use guilds as a way to gather people. Not only are guilds used for completing WoW activities, but many users have it function as a social community to keep in touch with their online friends."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Guild distribution and guild-class Distribution\r\n",
    "## Select entries that are in a guild\r\n",
    "in_a_guild = avatar_history[avatar_history['guild'] != -1]\r\n",
    "\r\n",
    "## Group playerbase by character char id, guild, and class\r\n",
    "tmp = in_a_guild.groupby(['char'])['guild','charclass'].max()\r\n",
    "\r\n",
    "## Find guild indices with 10 or more players\r\n",
    "guild_list = tmp['guild'].value_counts()[tmp['guild'].value_counts() >= 10].index\r\n",
    "\r\n",
    "## Create guild_class dataframe\r\n",
    "data =  {'guild_id': tmp['guild'].values ,\r\n",
    "         'class': tmp['charclass'].values,\r\n",
    "        }\r\n",
    "\r\n",
    "guild_class_df = pd.DataFrame(data)\r\n",
    "\r\n",
    "## Apply those guild_list indices to our dataframe\r\n",
    "guild_class_df = guild_class_df[guild_class_df['guild_id'].isin(guild_list)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the guild population distribution\r\n",
    "## Plot parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3},  palette = 'bright')\r\n",
    "ax = sns.distplot(guild_class_df['guild_id'], kde_kws = {\"color\": \"green\", \"lw\": 4, \"label\": \"KDE\"},\r\n",
    "                  hist_kws = {\"linewidth\": 6,\r\n",
    "                              \"alpha\": 1, \"color\": \"pink\",\r\n",
    "                              'label': 'Histogram'})\r\n",
    "\r\n",
    "plt.xlabel('Guild IDs', fontsize = 24)\r\n",
    "plt.ylabel('Frequency', fontsize = 24)\r\n",
    "plt.title('Guild Populations', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "# Add annotations for statistics\r\n",
    "plt.text(501, 0.00702,\r\n",
    "         'Min: ' + str(round(guild_class_df['guild_id'].value_counts().min(),1)),\r\n",
    "         size = 18, color = 'black')\r\n",
    "plt.text(501, 0.0073,\r\n",
    "         'Mean: ' + str(round(guild_class_df['guild_id'].value_counts().mean(),1)),\r\n",
    "         size = 18, color = 'black')\r\n",
    "plt.text(501, 0.0076,\r\n",
    "         'Max: ' + str(round(guild_class_df['guild_id'].value_counts().max(),1)),\r\n",
    "         size = 18, color = 'black')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the class distribution in guilds\r\n",
    "## Plot parameters\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3},  palette = 'bright')\r\n",
    "\r\n",
    "ax = sns.barplot(y = ['Warrior', 'Hunter',\r\n",
    "                      'Rogue', 'Mage',\r\n",
    "                      'Warlock', 'Paladin',\r\n",
    "                      'Shaman', 'Priest',\r\n",
    "                      'Druid', 'Death Knight'],\r\n",
    "                 x = guild_class_df['class'].value_counts()\r\n",
    "                )\r\n",
    "\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Classes', fontsize = 24)\r\n",
    "plt.title('Class distribution in guilds', fontsize = 24)\r\n",
    "plt.xticks(fontsize = 16)\r\n",
    "plt.yticks(fontsize = 16)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\r\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\r\n",
    "color = 'black')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a steady equilibrium of players between 70-79 having the highest frequency because the max level before November was 70. The max level was increased to 80 in November. Similar fluctuations are observed within the other leveling intervals between January and September, but a sharp peak in the 0-9 interval arises during October. A possible reason is the arrival of new players who are awaiting the expansion release in November.   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Daily Active Users"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def time_transform(x):\r\n",
    "    \"Function to split the date and time\"\r\n",
    "    y = x.split()[0]\r\n",
    "    return y[:-2] + '20' + y[-2:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Create new features date and time using the function above\r\n",
    "avatar_history['date'] = avatar_history['timestamp'].apply(time_transform)\r\n",
    "avatar_history['time'] = avatar_history['timestamp'].apply(lambda x: x.split()[1][:-4] + '0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the daily active users\r\n",
    "## Create pivot table to aggregate the number of users in each specific level interval.\r\n",
    "dau_pvt = avatar_history.pivot_table(index = 'date',\r\n",
    "                            columns = ['level_interval'],\r\n",
    "                            values = 'char',\r\n",
    "                            aggfunc = lambda x: x.value_counts().count()).fillna(0).astype(int)\r\n",
    "dau_pvt.reset_index(inplace=True)\r\n",
    "\r\n",
    "## Variables to extract all dates and account for missing dates in the pivot table\r\n",
    "all_dates = pd.Series(pd.date_range('01/01/08', freq = 'D', periods = 365))\r\n",
    "all_dates = all_dates.dt.strftime('%m/%d/%Y')\r\n",
    "missing_dates = list(set(all_dates) - set(dau_pvt.index.unique()))\r\n",
    "add_df = pd.DataFrame(columns = ['date'])\r\n",
    "add_df['date'] = missing_dates\r\n",
    "dau_pvt['date'] = pd.to_datetime(dau_pvt['date'])\r\n",
    "dau_pvt.sort_values(by=['date'], inplace = True)\r\n",
    "dau_pvt.reset_index(drop = True, inplace = True)\r\n",
    "dau_pvt['date'] = dau_pvt['date'].dt.strftime('%m/%d/%Y')\r\n",
    "\r\n",
    "\r\n",
    "## Plotly go object to plot the graph.\r\n",
    "fig = go.Figure()\r\n",
    "\r\n",
    "## Set colors of curves\r\n",
    "colormap = ['purple', 'orange',\r\n",
    "            'green', 'blue',\r\n",
    "            'teal', 'red',\r\n",
    "            'black', 'pink',\r\n",
    "            'yellow']\r\n",
    "\r\n",
    "## Set leveling intervals of curves\r\n",
    "columns = [ '0-9', '10-19',\r\n",
    "           '20-29', '30-39',\r\n",
    "           '40-49', '50-59',\r\n",
    "           '60-69', '70-79',\r\n",
    "           '80']\r\n",
    "\r\n",
    "## Plot each leveling curve with a respective color\r\n",
    "for color, column in zip(colormap, columns):\r\n",
    "    fig.add_trace(go.Scatter(\r\n",
    "                    x = dau_pvt['date'],\r\n",
    "                    y = dau_pvt[column],\r\n",
    "                    name = column,\r\n",
    "                    line_color = color,\r\n",
    "                    hoverinfo = 'name+x+y',\r\n",
    "                    opacity = 0.8))\r\n",
    "fig.update_layout(title_text = \"Daily User Activity over one-year\", \r\n",
    "                 xaxis = dict(\r\n",
    "                     tickmode = 'array',\r\n",
    "                     ## Place tick labels and locations\r\n",
    "                     ticktext = ['Jan', 'Feb',\r\n",
    "                                 'Mar', 'Apr',\r\n",
    "                                 'May', 'Jun',\r\n",
    "                                 'Jul', 'Aug',\r\n",
    "                                 'Sep', 'Oct',\r\n",
    "                                 'Nov', 'Dec'],\r\n",
    "                     \r\n",
    "                     tickvals = [1, 31,\r\n",
    "                                 60, 91,\r\n",
    "                                 121, 152,\r\n",
    "                                 182, 213,\r\n",
    "                                 244, 274,\r\n",
    "                                 304, 335]\r\n",
    "                 ),\r\n",
    "                  xaxis_rangeslider_visible = True)\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Monthly Active Users"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot monthly active users\r\n",
    "## Create pivot table to aggregate the number of users in each specific level interval.\r\n",
    "mau_pvt = avatar_history.pivot_table(index = 'date',\r\n",
    "                            columns = ['level_interval'],\r\n",
    "                            values = 'char',\r\n",
    "                            aggfunc = lambda x: x.value_counts().count()).fillna(0).astype(int)\r\n",
    "\r\n",
    "mau_pvt.reset_index(inplace = True)\r\n",
    "\r\n",
    "## Variables to extract all dates and account for missing dates in the pivot table\r\n",
    "all_dates = pd.Series(pd.date_range('01/01/08', freq = 'D', periods = 365))\r\n",
    "all_dates = all_dates.dt.strftime('%m/%d/%Y')\r\n",
    "missing_dates = list(set(all_dates) - set(mau_pvt.index.unique()))\r\n",
    "add_df = pd.DataFrame(columns=['date'])\r\n",
    "add_df['date'] = missing_dates\r\n",
    "mau_pvt['date'] = pd.to_datetime(mau_pvt['date'])\r\n",
    "mau_pvt.sort_values(by = ['date'], inplace = True)\r\n",
    "mau_pvt.reset_index(drop = True, inplace = True)\r\n",
    "mau_pvt['date'] = mau_pvt['date'].dt.strftime('%m/%d/%Y')\r\n",
    "\r\n",
    "## Map the months\r\n",
    "mau_pvt['date'] = (pd.to_datetime(mau_pvt['date']))\r\n",
    "\r\n",
    "d = {1: 'January', 2: 'February',\r\n",
    "     3: 'March', 4: 'April',\r\n",
    "     5: 'May', 6: 'June',\r\n",
    "     7: 'July', 8: 'August',\r\n",
    "     9: 'September', 10: 'October',\r\n",
    "     11: 'November', 12: 'December'}\r\n",
    "\r\n",
    "## Create the months dataframe for MAU\r\n",
    "mau_pvt['Month'] = mau_pvt['date'].dt.month.map(d)\r\n",
    "\r\n",
    "## Create label list for months\r\n",
    "yourlabels_list = [ 'January', 'February',\r\n",
    "                   'March',  'April',\r\n",
    "                   'May', 'June',\r\n",
    "                   'July',  'August',\r\n",
    "                   'September',  'October',\r\n",
    "                   'November',  'December']\r\n",
    "\r\n",
    "sum_months = mau_pvt.groupby('Month').sum()\r\n",
    "sorted_sum_month = pd.DataFrame(sum_months)\r\n",
    "\r\n",
    "sorted_sum_month.columns = [ '0-9', '10-19',\r\n",
    "                            '20-29', '30-39',\r\n",
    "                            '40-49', '50-59',\r\n",
    "                            '60-69',  '70-79',\r\n",
    "                            '80']\r\n",
    "\r\n",
    "sorted_sum_month.index.names = ['Month']\r\n",
    "sorted_sum_month = sorted_sum_month.reindex(yourlabels_list)\r\n",
    "\r\n",
    "## Plotly go object to plot the graph.\r\n",
    "fig = go.Figure()\r\n",
    "\r\n",
    "## Set colors for each curve\r\n",
    "colormap = ['purple', 'orange',\r\n",
    "            'green', 'blue',\r\n",
    "            'teal', 'red',\r\n",
    "            'black', 'pink',\r\n",
    "            'yellow']\r\n",
    "\r\n",
    "## Set leveling intervals of curves\r\n",
    "columns = [ '0-9', '10-19',\r\n",
    "           '20-29', '30-39',\r\n",
    "           '40-49', '50-59',\r\n",
    "           '60-69', '70-79',\r\n",
    "           '80']\r\n",
    "\r\n",
    "## Plot each leveling curve with a respective color\r\n",
    "for color, column in zip(colormap, columns):\r\n",
    "    fig.add_trace(go.Scatter(\r\n",
    "                    x = sorted_sum_month.index,\r\n",
    "                    y = sorted_sum_month[column],\r\n",
    "                    name = column,\r\n",
    "                    line_color = color,\r\n",
    "                    hoverinfo = 'name+x+y',\r\n",
    "                    opacity = 0.8))\r\n",
    "fig.update_layout(title_text = \"Monthly User Activity over one-year\", \r\n",
    "                 xaxis = dict(\r\n",
    "                     tickmode = 'array',              \r\n",
    "                     \r\n",
    "                 ),\r\n",
    "                  xaxis_rangeslider_visible = True)\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot hourly user activity\r\n",
    "## Create daily session dataframes\r\n",
    "tmp = avatar_history.groupby(by = ['date', 'time'])['char'].nunique().to_frame('char').reset_index()\r\n",
    "day_activity_mean = round(tmp.groupby(['time'], as_index = False)['char'].mean())\r\n",
    "day_activity_max = round(tmp.groupby(['time'], as_index = False)['char'].max())\r\n",
    "\r\n",
    "## Plotly go object to graph plot.\r\n",
    "fig = go.Figure()\r\n",
    "\r\n",
    "## Mean\r\n",
    "fig.add_trace(go.Scatter(\r\n",
    "    x = day_activity_mean['time'],\r\n",
    "    y = day_activity_mean['char'],\r\n",
    "    name = 'Average',\r\n",
    "    line_color = 'red',\r\n",
    "    hoverinfo = 'name+x+y',\r\n",
    "    opacity = 0.8))\r\n",
    "\r\n",
    "## Max \r\n",
    "fig.add_trace(go.Scatter(\r\n",
    "    x = day_activity_max['time'],\r\n",
    "    y = day_activity_max['char'],\r\n",
    "    name = 'Max',\r\n",
    "    line_color = 'purple',\r\n",
    "    hoverinfo = 'name+x+y',\r\n",
    "    opacity = 0.8))\r\n",
    "\r\n",
    "fig.update_layout(title_text = \"Hourly User Activity over one-year\", \r\n",
    "                  xaxis = dict(\r\n",
    "                      tickvals = [0, 6, 12, 18, 24, 30,\r\n",
    "                                  36, 42, 48, 54, 60,\r\n",
    "                                  66, 72, 78, 84, 90,\r\n",
    "                                  96, 102, 108, 114, 120,\r\n",
    "                                  126, 132, 138, 144],\r\n",
    "                  ),\r\n",
    "                  xaxis_rangeslider_visible = True)\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#### Average hours played\r\n",
    "# Group playerbase by character ID for average hours\r\n",
    "tmp = avatar_history.groupby(by = ['char'])['Day'].nunique()\r\n",
    "\r\n",
    "# Group playerbase by character ID for the number of unique days they have played\r\n",
    "total_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\r\n",
    "\r\n",
    "# Create dataframe for average_hours\r\n",
    "data =  {'char_id': tmp.index,\r\n",
    "         'total_timestamps': total_timestamps.values,\r\n",
    "         'unique_days': tmp.values\r\n",
    "        }\r\n",
    "\r\n",
    "average_hours_df = pd.DataFrame(data = data)\r\n",
    "\r\n",
    "# Create average_hour feature\r\n",
    "average_hours_df['Average_Hour'] = average_hours_df['total_timestamps'] * 10 / (60 * average_hours_df['unique_days'])\r\n",
    "\r\n",
    "# Plot the Average hours played\r\n",
    "plt.figure(figsize = (20,10))\r\n",
    "\r\n",
    "x = ['95% Percentile', '75% Percentile',\r\n",
    "     'Mean',  '50% Percentile',\r\n",
    "     '25% Percentile']\r\n",
    "\r\n",
    "y = [average_hours_df['Average_Hour'].quantile(0.95),\r\n",
    "     average_hours_df['Average_Hour'].quantile(0.75),\r\n",
    "     average_hours_df['Average_Hour'].mean(),\r\n",
    "     average_hours_df['Average_Hour'].quantile(0.50),\r\n",
    "     average_hours_df['Average_Hour'].quantile(0.25)]\r\n",
    "\r\n",
    "def absolute_value(val):\r\n",
    "    a  = str(round(val / 100 * 6.971746263215458, 3)) + \" hrs\"\r\n",
    "    return a\r\n",
    "\r\n",
    "# Create pie chart\r\n",
    "textprops = dict(size = 20 )\r\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ffb3cc']\r\n",
    "plt.pie(y, labels = x,\r\n",
    "        autopct = absolute_value, startangle = 180, textprops = textprops, colors = colors)\r\n",
    "plt.axis('equal') \r\n",
    "plt.tight_layout()\r\n",
    "plt.title('Daily Playtime', fontsize = 24)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot user frequency on weekdays\r\n",
    "## Create dataframe for most frequent day of the week\r\n",
    "tmp = avatar_history.groupby(by =['char'])['Weekday'].max().value_counts()\r\n",
    "\r\n",
    "data =  {'weekday': tmp.index,\r\n",
    "         'count': tmp.values\r\n",
    "        }\r\n",
    "\r\n",
    "weekdays_df = pd.DataFrame(data = data)\r\n",
    "\r\n",
    "## Map weekday\r\n",
    "d = {0: 'Monday', 1: 'Tuesday',\r\n",
    "     2: 'Wednesday', 3: 'Thursday',\r\n",
    "     4: 'Friday', 5: 'Saturday',\r\n",
    "     6: 'Sunday'}\r\n",
    "\r\n",
    "weekdays_df['weekday'] = weekdays_df['weekday'].map(d)\r\n",
    "tmp = weekdays_df\r\n",
    "\r\n",
    "## Plot the expected variance\r\n",
    "plt.figure(figsize = (20, 10))\r\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 2})\r\n",
    "\r\n",
    "order = ['Monday', 'Tuesday', \r\n",
    "         'Wednesday', 'Thursday',\r\n",
    "         'Friday', 'Saturday',\r\n",
    "         'Sunday']\r\n",
    "\r\n",
    "ax = sns.barplot(y = weekdays_df['weekday'], x = weekdays_df['count'],\r\n",
    "                 order = order,  palette = 'bright',\r\n",
    "                 edgecolor = 'pink')\r\n",
    "\r\n",
    "plt.xlabel('Count', fontsize = 24)\r\n",
    "plt.ylabel('Weekdays', fontsize = 24)\r\n",
    "plt.title('Distribution of Weekdays', fontsize = 24)\r\n",
    "plt.xticks( fontsize = 16)\r\n",
    "plt.yticks( fontsize = 16)\r\n",
    "\r\n",
    "'''Annotates a plot with percentages vertical layout.'''\r\n",
    "# create a list to collect the plt.patches data\r\n",
    "totals = []\r\n",
    "\r\n",
    "# find the values and append to list\r\n",
    "for i in ax.patches:\r\n",
    "    totals.append(i.get_width())\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "total = sum(totals)\r\n",
    "\r\n",
    "# set individual bar lables using above list\r\n",
    "for i in ax.patches:\r\n",
    "    # get_width pulls left or right; get_y pushes up or down\r\n",
    "    ax.text(i.get_width(), i.get_y() + 0.5, \\\r\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', fontsize = 16,\r\n",
    "color = 'black')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II: Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Survival Analysis\r\n",
    "## Feature creation\r\n",
    "### Earliest day and latest day of the year played\r\n",
    "tmp_day_earliest = avatar_history.groupby('char')['Day'].min()\r\n",
    "tmp_day_latest = avatar_history.groupby('char')['Day'].max()\r\n",
    "\r\n",
    "### Earliest month and Latest month of year played \r\n",
    "tmp_month_earliest = avatar_history.groupby('char')['Month'].min()\r\n",
    "tmp_month_latest = avatar_history.groupby('char')['Month'].max()\r\n",
    "\r\n",
    "### Unique amount of days played\r\n",
    "tmp_days = avatar_history.groupby('char')['Day'].nunique()\r\n",
    "\r\n",
    "### Are they in a guild or not\r\n",
    "tmp_guild = avatar_history.groupby('char')['guild'].max()\r\n",
    "\r\n",
    "### Max level\r\n",
    "tmp_level = avatar_history.groupby('char')['level_interval'].max()\r\n",
    "\r\n",
    "### Need this for the number of unique days played\r\n",
    "tmp_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\r\n",
    "\r\n",
    "# Create dataframe\r\n",
    "data =  {'Char_ID': tmp_month_latest.index,\r\n",
    "         'Unique_Days': tmp_days.values,\r\n",
    "         'Total_Timestamps': tmp_timestamps.values,\r\n",
    "         'Earliest_Month_Played': tmp_month_earliest.values,\r\n",
    "         'Latest_Month_Played': tmp_month_latest.values,\r\n",
    "         'Earliest_Day_Played': tmp_day_earliest.values,\r\n",
    "         'Latest_Day_Played': tmp_day_latest.values,\r\n",
    "         'Guild': tmp_guild.values,\r\n",
    "         'Max_Level': tmp_level.values\r\n",
    "        }\r\n",
    "\r\n",
    "sa_total = pd.DataFrame(data)\r\n",
    "\r\n",
    "### Difference in latest day played and earliest day played and absolute value to find the total subscribed time.\r\n",
    "sa_total['Difference'] = (sa_total['Latest_Day_Played'] - sa_total['Earliest_Day_Played']).abs()\r\n",
    "\r\n",
    "### Filter out the data whom have lower than 30 days of played time (free-trial accounts)\r\n",
    "sa_total = sa_total.loc[(sa_total['Difference'] > 30)]\r\n",
    "sa_total['Guild'] = sa_total['Guild'].apply(lambda x: 0 if x == -1 else 1)\r\n",
    "\r\n",
    "### Create average_hour feature\r\n",
    "sa_total['Average_Hour'] = sa_total['Total_Timestamps'] * 10 / (60 * sa_total['Unique_Days'])\r\n",
    "\r\n",
    "### Create playing density\r\n",
    "sa_total['Average_Playing_Density'] = sa_total['Unique_Days']/ (((sa_total['Latest_Month_Played'] - sa_total['Earliest_Month_Played'] + 1).abs())/12 * 366)\r\n",
    "\r\n",
    "### Classify churn as someone who hasn't logged in various periods, 2, 3, 4, 6\r\n",
    "#### 2 month period\r\n",
    "sa_total['Churn2'] = (sa_total['Latest_Month_Played'] >= 11 )\r\n",
    "sa_total['Churn2'] = sa_total['Churn2'].apply(lambda x: 0 if x == True else 1)\r\n",
    "\r\n",
    "#### 3 month period\r\n",
    "sa_total['Churn3'] = (sa_total['Latest_Month_Played'] >= 10)\r\n",
    "sa_total['Churn3'] = sa_total['Churn3'].apply(lambda x: 0 if x == True else 1)\r\n",
    "\r\n",
    "#### 4 month period\r\n",
    "sa_total['Churn4'] = (sa_total['Latest_Month_Played'] >= 9)\r\n",
    "sa_total['Churn4'] = sa_total['Churn4'].apply(lambda x: 0 if x == True else 1)\r\n",
    "\r\n",
    "#### 6 month period\r\n",
    "sa_total['Churn6'] = (sa_total['Latest_Month_Played'] >= 7)\r\n",
    "sa_total['Churn6'] = sa_total['Churn6'].apply(lambda x: 0 if x == True else 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Churn Periods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Survival Analysis\r\n",
    "## Kaplan-Meier Analysis\r\n",
    "### KMF\r\n",
    "kmf = KaplanMeierFitter()\r\n",
    "\r\n",
    "### Plot Parameters\r\n",
    "sns.set_context(\"talk\")\r\n",
    "ax = plt.subplot()\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Player Departure Periods', fontsize = 24)\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\r\n",
    "\r\n",
    "### Plotting KM curves with various churn periods\r\n",
    "churn_list = ['Churn2', 'Churn3', 'Churn4', 'Churn6']\r\n",
    "churn_labels = ['2-month period', '3-month period', '4-month period', '6-month period']\r\n",
    "colormap = ['red', 'blue', 'green', 'orange']\r\n",
    "for churn, label, color in zip(churn_list, churn_labels, colormap):\r\n",
    "    kmf.fit(sa_total['Difference'], sa_total[churn], label = label)\r\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color)\r\n",
    "    \r\n",
    "### Plotting Annotations\r\n",
    "plt.vlines(303, ymin= 0.40, ymax= 0.46, linestyle = 'dotted', color = 'red')\r\n",
    "plt.vlines(273, ymin= 0.40, ymax= 0.59, linestyle = 'dotted', color = 'blue')\r\n",
    "plt.vlines(243, ymin= 0.40, ymax= 0.67, linestyle = 'dotted', color = 'green')\r\n",
    "plt.vlines(177, ymin= 0.40, ymax= 0.81, linestyle = 'dotted', color = 'orange')\r\n",
    "plt.text(276, 0.40, '30 days', color = 'red')\r\n",
    "plt.text(246, 0.40, '30 days', color = 'blue')\r\n",
    "plt.text(186, 0.40, '60 days', color = 'green', fontsize = 38)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Survival Analysis\r\n",
    "## Kaplan-Meier Analysis\r\n",
    "### KMF\r\n",
    "kmf = KaplanMeierFitter()\r\n",
    "\r\n",
    "### Plotting parameters\r\n",
    "sns.set_context(\"talk\")\r\n",
    "ax = plt.subplot()\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Guild', fontsize = 24)\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\r\n",
    "\r\n",
    "### Plotting KM curves if they are in a guild or not\r\n",
    "T_0 = sa_total[sa_total['Guild'] == 0]['Difference']\r\n",
    "C_0 = sa_total[sa_total['Guild'] == 0]['Churn2']\r\n",
    "T_1 = sa_total[sa_total['Guild'] == 1]['Difference']\r\n",
    "C_1 = sa_total[sa_total['Guild'] == 1]['Churn2']\r\n",
    "\r\n",
    "time_limit = 303\r\n",
    "labels = ['Guild', 'No Guild']\r\n",
    "colormap = ['red', 'blue']\r\n",
    "duration = [T_0, T_1]\r\n",
    "event = [C_0, C_1]\r\n",
    "position = [(100, 0.4), (180, 0.6)]\r\n",
    "\r\n",
    "for T, C, label, label_position, color in zip(duration, event, labels, position, colormap):\r\n",
    "    kmf.fit(T, C, label = label)\r\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color)\r\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\r\n",
    "          t = time_limit, ax = ax,\r\n",
    "          label = '_nolegend_', text_position = label_position)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Guild Departure Ratio: \" + str((242.407/182.265)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Survival Analysis\r\n",
    "## Kaplan-Meier Analysis\r\n",
    "### KMF\r\n",
    "kmf = KaplanMeierFitter()\r\n",
    "\r\n",
    "### Plotting parameters\r\n",
    "sns.set_context(\"talk\")\r\n",
    "ax = plt.subplot()\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Levels', fontsize = 24)\r\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\r\n",
    "plt.ylabel(\"Probability a Player is Still Active\", fontsize = 18)\r\n",
    "\r\n",
    "### Plotting KM curves if they are in a guild or not\r\n",
    "T_09 = sa_total[sa_total['Max_Level'] == '0-9']['Difference']\r\n",
    "C_09 = sa_total[sa_total['Max_Level'] == '0-9']['Churn2']\r\n",
    "T_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Difference']\r\n",
    "C_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Churn2']\r\n",
    "T_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Difference']\r\n",
    "C_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Churn2']\r\n",
    "T_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Difference']\r\n",
    "C_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Churn2']\r\n",
    "T_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Difference']\r\n",
    "C_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Churn2']\r\n",
    "T_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Difference']\r\n",
    "C_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Churn2']\r\n",
    "T_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Difference']\r\n",
    "C_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Churn2']\r\n",
    "T_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Difference']\r\n",
    "C_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Churn2']\r\n",
    "\r\n",
    "time_limit = 303\r\n",
    "\r\n",
    "labels = ['0-9', '10-19',\r\n",
    "          '20-29', '30-39',\r\n",
    "          '40-49', '50-59',\r\n",
    "          '60-69', '70-79']\r\n",
    "\r\n",
    "colormap = ['red', 'blue',\r\n",
    "            'magenta', 'orange',\r\n",
    "            'teal', 'purple',\r\n",
    "            'green', 'pink']\r\n",
    "\r\n",
    "duration = [T_09, T_1019, T_2029, T_3039, T_4049, T_5059, T_6069, T_7079] \r\n",
    "event = [C_09, C_1019, C_2029, C_3039, C_4049, C_5059, C_6069, C_7079]\r\n",
    "\r\n",
    "for T, C, label, color in zip(duration, event, labels, colormap):\r\n",
    "    kmf.fit(T, C, label = label)\r\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color, ci_show = True )\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Survival Analysis\r\n",
    "## Kaplan-Meier Analysis\r\n",
    "### KMF\r\n",
    "kmf = KaplanMeierFitter()\r\n",
    "\r\n",
    "### Plot parameters\r\n",
    "sns.set_context(\"talk\")\r\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(figsize = (20, 10), nrows=2,\r\n",
    "                                                                 ncols=4, sharex=True,\r\n",
    "                                                                 sharey=True)\r\n",
    "fig.suptitle('Kaplan-Meier Estimate of Customer Retention by Levels')\r\n",
    "\r\n",
    "# Plotting KM curves at various levels\r\n",
    "T_09 = sa_total[sa_total['Max_Level'] == '0-9']['Difference']\r\n",
    "C_09 = sa_total[sa_total['Max_Level'] == '0-9']['Churn2']\r\n",
    "T_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Difference']\r\n",
    "C_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Churn2']\r\n",
    "T_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Difference']\r\n",
    "C_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Churn2']\r\n",
    "T_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Difference']\r\n",
    "C_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Churn2']\r\n",
    "T_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Difference']\r\n",
    "C_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Churn2']\r\n",
    "T_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Difference']\r\n",
    "C_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Churn2']\r\n",
    "T_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Difference']\r\n",
    "C_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Churn2']\r\n",
    "T_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Difference']\r\n",
    "C_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Churn2']\r\n",
    "\r\n",
    "time_limit = 303\r\n",
    "\r\n",
    "labels = ['0-9', '10-19',\r\n",
    "          '20-29', '30-39',\r\n",
    "          '40-49', '50-59',\r\n",
    "          '60-69', '70-79']\r\n",
    "\r\n",
    "colormap = ['red', 'blue',\r\n",
    "            'magenta', 'orange',\r\n",
    "            'teal', 'purple',\r\n",
    "            'green', 'pink']\r\n",
    "position = [(100, 0.4), (180, 0.6)]\r\n",
    "\r\n",
    "duration = [T_09, T_1019, T_2029, T_3039, T_4049, T_5059, T_6069] \r\n",
    "event = [C_09, C_1019, C_2029, C_3039, C_4049, C_5059, C_6069]\r\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7]\r\n",
    "\r\n",
    "for T, C, label, color, ax in zip(duration, event, labels, colormap, axes):\r\n",
    "    # Plot 70-79 KM curve\r\n",
    "    kmf.fit(T_7079, C_7079, label = '70-79')\r\n",
    "    kmf.plot(figsize = (40,20), ax = ax, color = 'black', ci_show=True )\r\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\r\n",
    "          t = time_limit, ax = ax,\r\n",
    "          label = '_nolegend_', text_position = (125, 0.92), fontsize = 10)\r\n",
    "    # Plot level interval KM curve\r\n",
    "    kmf.fit(T, C, label = label)\r\n",
    "    kmf.plot(figsize = (40,20), ax = ax, color = color, ci_show=True )\r\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\r\n",
    "          t = time_limit, ax = ax,\r\n",
    "          label = '_nolegend_', text_position = (0, 0.25), fontsize = 10)\r\n",
    "    \r\n",
    "    # Set plot parameters\r\n",
    "    ax.set_title(label, y = 1.05, fontsize = 16)\r\n",
    "    ax.set_xlabel('Duration (Days)', fontsize = 16)\r\n",
    "    ax.set_ylabel(\"Probability a Player is Still Active\", fontsize = 14)\r\n",
    "    ax.legend(bbox_to_anchor = [0.55, 0.27])\r\n",
    "    ax8.axis('off')\r\n",
    "\r\n",
    "    \r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Create an array and transpose values to make it a two-column format\r\n",
    "churn_values = [round(262.447 / 189.470, 3), round(262.447 / 170.453, 3),\r\n",
    "        round(262.447 / 191.560, 3), round(262.447 / 207.947, 3),\r\n",
    "        round(262.447 / 212.784, 3), round(262.447 / 235.308, 3),\r\n",
    "        round(262.447 / 228.042, 3)]\r\n",
    "churn_values = np.array(churn_values)\r\n",
    "\r\n",
    "## Create level intervals label\r\n",
    "level_intervals = ['0-9', '10-19',\r\n",
    "                            '20-29', '30-39',\r\n",
    "                            '40-49', '50-59',\r\n",
    "                            '60-69']\r\n",
    "    \r\n",
    "## Create plotly table object\r\n",
    "level_churn = go.Figure(data = [go.Table(\r\n",
    "    header = dict(values = ['Level Interval', 'Churn Ratio'],\r\n",
    "                  line_color = 'darkslategray',\r\n",
    "                  fill_color = 'lightskyblue',\r\n",
    "                  align = 'left'),\r\n",
    "    cells = dict(values = [level_intervals, churn_values],\r\n",
    "                 line_color = 'darkslategray',\r\n",
    "                 fill_color = 'lightcyan',\r\n",
    "                 align = 'left'))\r\n",
    "])\r\n",
    "\r\n",
    "level_churn.update_layout(width = 800, height = 500,\r\n",
    "                          title = 'Table 2: Churn Ratios with Level Intervals')\r\n",
    "level_churn.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create dataframe to apply ML\r\n",
    "## Group playerbase by character ID for average hours\r\n",
    "tmp = avatar_history.groupby(by = ['char'])['Day'].nunique()\r\n",
    "tmp_guild = avatar_history.groupby('char')['guild'].max()\r\n",
    "tmp_max_level = avatar_history.groupby('char')['level'].max()\r\n",
    "tmp_max_month = avatar_history.groupby('char')['Month'].max()\r\n",
    "tmp_min_month = avatar_history.groupby('char')['Month'].min()\r\n",
    "\r\n",
    "## Group playerbase by character ID for the number of unique days they have played\r\n",
    "total_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\r\n",
    "\r\n",
    "## Create dataframe for average_hours\r\n",
    "data =  {'char_id': tmp.index,\r\n",
    "         'guild': tmp_guild.values,\r\n",
    "         'total_timestamps': total_timestamps.values,\r\n",
    "         'unique_days': tmp.values,\r\n",
    "         'max_level': tmp_max_level.values,\r\n",
    "         'min_month': tmp_min_month.values,\r\n",
    "         'max_month': tmp_max_month.values,\r\n",
    "        }\r\n",
    "\r\n",
    "average_hours_df = pd.DataFrame(data = data)\r\n",
    "\r\n",
    "## Create average_hour feature\r\n",
    "average_hours_df['Average_Hour'] = average_hours_df['total_timestamps'] * 10 / (60 * average_hours_df['unique_days'])\r\n",
    "\r\n",
    "## Create playing density\r\n",
    "average_hours_df['Average_Playing_density'] = average_hours_df['unique_days'] / (((average_hours_df['max_month'] - average_hours_df['min_month'] + 1).abs()) / 12 * 366)\r\n",
    "\r\n",
    "## Are they in a guild or not\r\n",
    "average_hours_df['guild'] = average_hours_df['guild'].apply(lambda x: 0 if x == -1 else 1)\r\n",
    "\r\n",
    "## Playing for 6 months and longer (y output)\r\n",
    "average_hours_df['Playing_after_6_months'] = (average_hours_df['max_month'] - average_hours_df['min_month'] +1).abs().apply(lambda x: 1 if x >= 6 else 0)\r\n",
    "\r\n",
    "## Create train and testing sets, and include stratification (0.80 / 0/20)\r\n",
    "X = average_hours_df[['guild', 'max_level', 'Average_Hour', 'Average_Playing_density']]\r\n",
    "y = average_hours_df['Playing_after_6_months']\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10, stratify = y)\r\n",
    "\r\n",
    "## Scale the data\r\n",
    "col_names = ['guild','max_level', 'Average_Hour', 'Average_Playing_density']\r\n",
    "features = X_train[col_names]\r\n",
    "features_test = X_test[col_names]\r\n",
    "ct = ColumnTransformer([\r\n",
    "        ('somename', StandardScaler(), ['max_level', 'Average_Hour', 'Average_Playing_density'])\r\n",
    "    ], remainder = 'passthrough')\r\n",
    "X_train_scaled = ct.fit_transform(features)\r\n",
    "X_test_scaled = ct.transform(features_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_hours_df.to_csv('churn.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logistic Regression Pipeline\r\n",
    "## Instantiate logistic regression model\r\n",
    "clf_LR = LogisticRegression(random_state = 0, solver = 'liblinear')\r\n",
    "\r\n",
    "## First step of pipeline recursive feature elimination with cross validation (10-fold)\r\n",
    "rfecv = RFECV(estimator = clf_LR, \r\n",
    "              step = 1, \r\n",
    "              cv = StratifiedKFold(10), \r\n",
    "              scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Second step of pipeline grid search using cross validation (10-fold)\r\n",
    "CV_rfc = GridSearchCV(clf_LR, \r\n",
    "                      param_grid = {'penalty': ['l2', 'l1'],\r\n",
    "                                    'C': [0.001,.009,0.01,.09,.5, 0.8, 1,5,10,25]},\r\n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Instantiate Pipeline\r\n",
    "pipeline = Pipeline([('feature_sele', rfecv),('clf_LR_cv', CV_rfc)])\r\n",
    "pipeline.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Assign model predictions\r\n",
    "y_pred_acc = pipeline.predict(X_test_scaled)\r\n",
    "\r\n",
    "## Best parameters and features for the model\r\n",
    "print(rfecv.get_support()) \r\n",
    "print('Best Penalty:', CV_rfc.best_estimator_.get_params()['penalty'])\r\n",
    "print('Best C:', CV_rfc.best_estimator_.get_params()['C'])\r\n",
    "print(CV_rfc.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Best Logistic Regression parameters \r\n",
    "## Create the model instance\r\n",
    "clf_LR = LogisticRegression(random_state = 0, solver = 'liblinear',\r\n",
    "                            C = 25, penalty = 'l2')\r\n",
    "\r\n",
    "## Get the ROC by k-fold cross validation on the training set\r\n",
    "cv_scores = cross_val_score(clf_LR, X_train_scaled,\r\n",
    "                            y_train, cv = StratifiedKFold(10),\r\n",
    "                            scoring = 'roc_auc')\r\n",
    "\r\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\r\n",
    "\r\n",
    "## Fit the model\r\n",
    "clf_LR.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "# Get the model predictions\r\n",
    "y_pred_acc = clf_LR.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Classification metrics\r\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\r\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\r\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\r\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\r\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_LR.predict_proba(X_test_scaled)[:,1])))\r\n",
    "\r\n",
    "# Logistic Regression (Grid Search) Confusion matrix\r\n",
    "confusion_matrix(y_test,y_pred_acc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Support Vector Machine Pipeline\r\n",
    "## Instantiate Support Vector Machine Pipeline\r\n",
    "\r\n",
    "clf_SVM = svm.SVC(kernel = 'linear')\r\n",
    "\r\n",
    "## First step of pipeline recursive feature elimination with cross validation (10-fold)\r\n",
    "rfecv = RFECV(estimator = clf_SVM, \r\n",
    "              step = 1, \r\n",
    "              cv = StratifiedKFold(10), \r\n",
    "              scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Second step of pipeline grid search using cross validation (10-fold)\r\n",
    "CV_rfc = GridSearchCV(clf_SVM, \r\n",
    "                      param_grid = \r\n",
    "                      {\r\n",
    "                          'kernel': ['linear', 'rbf', 'sigmoid'],\r\n",
    "                          'C': [0.001,.009,0.01,.09,.5, 0.8, 1,5,10,25]      \r\n",
    "                      },\r\n",
    "                      \r\n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Instantiate Pipeline\r\n",
    "pipeline = Pipeline([('feature_sele', rfecv),('clf_SVM_cv', CV_rfc)])\r\n",
    "pipeline.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Assign model predictions\r\n",
    "y_pred_acc = pipeline.predict(X_test_scaled)\r\n",
    "\r\n",
    "## Best parameters and features for the model\r\n",
    "print(rfecv.get_support()) \r\n",
    "print(CV_rfc.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Best SVM parameters \r\n",
    "## Set new features\r\n",
    "X_train_SVM = np.column_stack((X_train_scaled[:,:2],\r\n",
    "                               X_train_scaled[:,:][0:, -1].reshape(29883, 1)))\r\n",
    "\r\n",
    "X_test_SVM = np.column_stack((X_test_scaled[:,:2],\r\n",
    "                              X_test_scaled[:,:][0:, -1].reshape(7471, 1)))\r\n",
    "\r\n",
    "## Create the model instance\r\n",
    "clf_SVM = svm.SVC(kernel = 'linear', C = 0.009)\r\n",
    "\r\n",
    "## Get the ROC by k-fold cross validation on the training set\r\n",
    "cv_scores = cross_val_score(clf_SVM, X_train_SVM,\r\n",
    "                            y_train, cv = StratifiedKFold(10),\r\n",
    "                            scoring = 'roc_auc')\r\n",
    "\r\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\r\n",
    "\r\n",
    "## Fit the model\r\n",
    "clf_SVM.fit(X_train_SVM, y_train)\r\n",
    "\r\n",
    "## Get the model predictions\r\n",
    "y_pred_acc = clf_SVM.predict(X_test_SVM)\r\n",
    "\r\n",
    "## Classification metrics\r\n",
    "print('Accuracy Scoree : ' + str(precision_score(y_test, y_pred_acc)))\r\n",
    "print('Recall Score : : ' + str(accuracy_score(y_test, y_pred_acc)))\r\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\r\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\r\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\r\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_SVM.decision_function(X_test_SVM))))\r\n",
    "\r\n",
    "#Logistic Regression (Grid Search) Confusion matrix\r\n",
    "confusion_matrix(y_test, y_pred_acc)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# K-Nearest Neighbors Pipeline\r\n",
    "## Instantiate K-Nearest Neighbors Pipeline\r\n",
    "clf_KNN = KNeighborsClassifier()\r\n",
    "\r\n",
    "## Set parameters for grid search\r\n",
    "leaf_size = list(range(1, 50))\r\n",
    "n_neighbors = list(range(1, 30))\r\n",
    "p = [1,2]\r\n",
    "hyperparameters = dict(leaf_size = leaf_size, n_neighbors = n_neighbors,\r\n",
    "                       p = p)\r\n",
    "\r\n",
    "### First step of pipeline\r\n",
    "CV_rfc = GridSearchCV(clf_KNN, \r\n",
    "                      param_grid = hyperparameters,\r\n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Instantiate Pipeline\r\n",
    "pipeline = Pipeline([(('clf_KNN_cv', CV_rfc))])\r\n",
    "pipeline.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Best parameters and features for the model\r\n",
    "print(CV_rfc.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Best KNN parameters \r\n",
    "## Create the model instance\r\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors = 24, leaf_size = 2,\r\n",
    "                               p = 1)\r\n",
    "\r\n",
    "cv_scores = cross_val_score(clf_KNN, X_train_scaled,\r\n",
    "                            y_train, cv = StratifiedKFold(10),\r\n",
    "                            scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Get the ROC by k-fold cross validation on the training set\r\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\r\n",
    "\r\n",
    "## Fit the model\r\n",
    "clf_KNN.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Get the model predictions\r\n",
    "y_pred_acc = clf_KNN.predict(X_test_scaled)\r\n",
    "\r\n",
    "## Classification metrics\r\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\r\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\r\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\r\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\r\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1])))\r\n",
    "\r\n",
    "# Logistic Regression (Grid Search) Confusion matrix\r\n",
    "confusion_matrix(y_test,y_pred_acc)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest Pipeline\r\n",
    "## Instantiate Random Forest Pipeline\r\n",
    "clf_RF = RandomForestClassifier()\r\n",
    "\r\n",
    "# Randomized grid search of parameters\r\n",
    "grid_param = {\r\n",
    "    'n_estimators': [100, 300, 500, 800, 1000, 1200],\r\n",
    "    'max_features': [1, 2, 3, 4],\r\n",
    "    'criterion': ['gini', 'entropy'],\r\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\r\n",
    "    'min_samples_split' : [2, 5, 10, 15, 20],\r\n",
    "    'bootstrap': [True, False]\r\n",
    "}\r\n",
    "\r\n",
    "CV_rfc = clf_RF = RandomizedSearchCV(clf_RF, grid_param,\r\n",
    "                                     random_state = 0, cv = StratifiedKFold(10))\r\n",
    "\r\n",
    "## Instantiate Pipeline\r\n",
    "pipeline = Pipeline([('clf_RF_cv',CV_rfc)])\r\n",
    "pipeline.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Best parameters and features for the model\r\n",
    "print(CV_rfc.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Best RF parameters \r\n",
    "\r\n",
    "## Create the model instance\r\n",
    "clf_RF = RandomForestClassifier(n_estimators = 300, min_samples_split = 15,\r\n",
    "                                max_depth = None, criterion = 'entropy',\r\n",
    "                                bootstrap = True, random_state = 10)\r\n",
    "\r\n",
    "cv_scores = cross_val_score(clf_KNN, X_train_scaled,\r\n",
    "                            y_train, cv = StratifiedKFold(10),\r\n",
    "                            scoring = 'roc_auc')\r\n",
    "\r\n",
    "## Get the ROC score by k-fold cross validation on the training set\r\n",
    "print('cv_scores mean :{}'.format(np.mean(cv_scores)))\r\n",
    "\r\n",
    "## Fit the model\r\n",
    "clf_RF.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "## Get the model predictions\r\n",
    "y_pred_acc = clf_RF.predict(X_test_scaled)\r\n",
    "\r\n",
    "## Classification metrics\r\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\r\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\r\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\r\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\r\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_RF.predict_proba(X_test_scaled)[:,1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reciever Operating Characteristics\r\n",
    "## Plot parameters\r\n",
    "sns.set_context(\"talk\")\r\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(figsize = (20, 10), nrows=2, ncols=2, sharex=True, sharey=True)\r\n",
    "fig.suptitle('Receiver Operating Characteristic (ROC) Curve')\r\n",
    "plt.subplots_adjust(\r\n",
    "wspace = 0.2,  # the amount of width reserved for space between subplots,\r\n",
    "       # expressed as a fraction of the average axis width\r\n",
    "hspace = 0.3 , # the amount of height reserved for space between subplots,\r\n",
    "              # expressed as a fraction of the average axis height)\r\n",
    ") \r\n",
    "\r\n",
    "## Plotting ROC curves with various algorithms\r\n",
    "fper_LR, tper_LR, thresholds_LR = roc_curve(y_test, clf_LR.predict_proba(X_test_scaled)[:,1]) \r\n",
    "\r\n",
    "fper_SVM, tper_SVM, thresholds_SVM = roc_curve(y_test, clf_SVM.decision_function(X_test_SVM)) \r\n",
    "\r\n",
    "fper_KNN, tper_KNN, thresholds_KNN = roc_curve(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1]) \r\n",
    "\r\n",
    "fper_RF, tper_RF, thresholds_RF = roc_curve(y_test, clf_RF.predict_proba(X_test_scaled)[:,1]) \r\n",
    "\r\n",
    "titles = ['LR', 'SVM',\r\n",
    "          'KNN', 'RF',\r\n",
    "]\r\n",
    "\r\n",
    "colormap = ['red', 'blue',\r\n",
    "            'magenta', 'orange',\r\n",
    "           ]\r\n",
    "position = [(100, 0.4), (180, 0.6)]\r\n",
    "\r\n",
    "fpr = [fper_LR, fper_SVM, fper_KNN, fper_RF] \r\n",
    "tpr = [tper_LR, tper_SVM, tper_KNN, tper_RF]\r\n",
    "\r\n",
    "axes = [ax1, ax2, ax3, ax4]\r\n",
    "roc_scores = [str('AUC: ') + str(round(roc_auc_score(y_test, clf_LR.predict_proba(X_test_scaled)[:,1]), 4)),\r\n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_SVM.decision_function(X_test_SVM)), 4)),\r\n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1]), 4)), \r\n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_RF.predict_proba(X_test_scaled)[:,1]), 4))\r\n",
    "             ]\r\n",
    "for fp, tp, label, title, color, ax in zip(fpr, tpr, roc_scores, titles, colormap, axes):\r\n",
    "    ax.plot(fp, tp, color= color, label= label)\r\n",
    "    ax.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\r\n",
    "    # Set plot parameters\r\n",
    "    ax.set_title(title, y = 1.05, fontsize = 16)\r\n",
    "    ax.set_xlabel('False Positive Rate', fontsize = 14, labelpad = 10)\r\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize = 14, labelpad = 15)\r\n",
    "    ax.legend(bbox_to_anchor = [1, 0.27])\r\n",
    "\r\n",
    "       \r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Table of the ROC AUC scores of various machine learning algorithms\r\n",
    "## Create an array and transpose values to make it a two-column format\r\n",
    "accuracy_values = [0.8451, 0.6384,\r\n",
    "        0.8814, 0.9171]\r\n",
    "accuracy_values = np.array(accuracy_values)\r\n",
    "\r\n",
    "\r\n",
    "roc_values_train = [0.8532, 0.8454,\r\n",
    "        0.9407, 0.9254]\r\n",
    "\r\n",
    "roc_values_test = [0.8503, 0.8417,\r\n",
    "        0.9366, 0.9665]\r\n",
    "\r\n",
    "roc_values_test = np.array(roc_values_test)\r\n",
    "\r\n",
    "method = ['Logistic Regression', 'Support Vector Machine',\r\n",
    "                            'K-Nearest Neighbors', 'Random Forest',]\r\n",
    "\r\n",
    "## Create plotly table object\r\n",
    "roc_auc = go.Figure(data = [go.Table(\r\n",
    "    header = dict(values = [['Method'], ['Accuracy'], ['ROC_AUC', ['10-fold CV']], ['', ['Testing']]],\r\n",
    "                  line_color = 'darkslategray',\r\n",
    "                  fill_color = 'lightskyblue',\r\n",
    "                  align = 'left'),\r\n",
    "    cells = dict(values = [method, accuracy_values, roc_values_train, roc_values_test],\r\n",
    "                 line_color = 'darkslategray',\r\n",
    "                 fill_color = 'lightcyan',\r\n",
    "                 align = 'left'))\r\n",
    "])\r\n",
    "\r\n",
    "roc_auc.update_layout(width = 800, height = 500,\r\n",
    "                      title = 'Table 3: ROC AUC scores with various machine learning algorithms.')\r\n",
    "roc_auc.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}